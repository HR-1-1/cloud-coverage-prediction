{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Preprocess.ipynb","provenance":[{"file_id":"1-lpzvMSZaUAm47zu-1v-H288Jomv0OqH","timestamp":1646331247688}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"n90v2vLUihJb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634913897967,"user_tz":-330,"elapsed":17862,"user":{"displayName":"Archish S me20b032","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9ll1qEcdMw2M-lzXJv5aJCpZWOiRrS0LtyzYpWw=s64","userId":"01577508935431199324"}},"outputId":"6e654a09-fb4a-4fe2-96a7-3c1951127a11"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"BBHING00h5er"},"source":["from IPython.display import clear_output\n","\n","!gdown --id 1z2-yb17G56b5Etqpkrj2sX1VC3CH8BZL\n","!unzip /content/processed_dataset.zip\n","!mv /content/content/dataset /content/dataset\n","!rm -rf /content/processed_dataset.zip\n","!rm -rf /content/content/\n","!rm -rf /content/dataset/processed_test.csv\n","!rm -rf /content/dataset/processed_train.csv\n","!mv /content/dataset/test/test.csv /content/dataset/test.csv\n","\n","!pip install pyprind\n","\n","clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Po-I-Rz1p6H"},"source":["# from IPython.display import clear_output\n","\n","# !gdown --id 1BwrMSrNb1Kz27AU0JBkS7V-Va7iagoo1\n","# !mkdir /content/dataset\n","# !unzip /content/processed_dataset_new.zip -d /content/dataset\n","# !rm -rf /content/processed_dataset_new.zip\n","\n","# !pip install pyprind\n","\n","# clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mwzygUNqkiwl"},"source":["---"]},{"cell_type":"code","metadata":{"id":"aTI3v-chkV0z"},"source":["import pandas as pd\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","import os\n","import glob\n","from tqdm import trange\n","import pyprind\n","\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DZPf3euKpfA4"},"source":["def get_date(date):\n","    M, D = date.split('/')\n","    M = \"0\" + M if len(M)==1 else M\n","    D = \"0\" + D if len(D)==1 else D\n","    return M+D\n","\n","def get_time(time):\n","    M, H = time.split(':')\n","    return M + H + \"00\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G7OFoyhBoWMt"},"source":["___"]},{"cell_type":"code","metadata":{"id":"gLSiyqn4ZKI0"},"source":["def make_dict_train(data):\n","    entry = {} \n","\n","    entry[\"Date\"] = data[0][0]\n","    entry[\"Time\"] = data[1]\n","    entry[\"Global CMP22\"] = data[2]\n","    entry[\"Direct sNIP\"] = data[3]\n","    entry[\"Azimuth Angle\"] = data[4]\n","    entry[\"Tower Dry Bulb Temperature\"] = data[5]\n","    entry[\"Tower Wet Bulb Temperature\"] = data[6]\n","    entry[\"Tower Dew Point Temperature\"] = data[7]\n","    entry[\"Tower RH\"] = data[8]\n","    entry[\"Total Cloud Cover\"] = data[9]\n","    entry[\"Peak Wind Speed\"] = data[10]\n","    entry[\"Avgerage Wind Direction\"] = data[11]\n","    entry[\"Station Pressure\"] = data[12]\n","    entry[\"Precipitation\"] = data[13]\n","    entry[\"Snow Depth\"] = data[14]\n","    entry[\"Moisture\"] = data[15]\n","    entry[\"Albedo\"] = data[16]\n","\n","    return entry\n","\n","def make_dict_test(data):\n","    entry = {}\n","    \n","    entry[\"Time\"] = list(map(int, data[0]))\n","    entry[\"Global CMP22\"] = data[1]\n","    entry[\"Direct sNIP\"] = data[2]\n","    entry[\"Azimuth Angle\"] = data[3]\n","    entry[\"Tower Dry Bulb Temperature\"] = data[4]\n","    entry[\"Tower Wet Bulb Temperature\"] = data[5]\n","    entry[\"Tower Dew Point Temperature\"] = data[6]\n","    entry[\"Tower RH\"] = data[7]\n","    entry[\"Total Cloud Cover\"] = data[8]\n","    entry[\"Peak Wind Speed\"] = data[9]\n","    entry[\"Avgerage Wind Direction\"] = data[10]\n","    entry[\"Station Pressure\"] = data[11]\n","    entry[\"Precipitation\"] = data[12]\n","    entry[\"Snow Depth\"] = data[13]\n","    entry[\"Moisture\"] = data[14]\n","    entry[\"Albedo\"] = data[15]\n","\n","    return entry"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ui4tlQ5s3H5T"},"source":["def normalize_columns(data):\n","    data = data.copy()\n","    smooth = 1e-8\n","    for column in data.columns:\n","        if column == 'DATE (MM/DD)' or column == 'MST' or column == 'Time [Mins]':\n","            continue\n","        elif column == 'Global CMP22 (vent/cor) [W/m^2]':\n","            data[column] = (data[column] - (-5) + smooth ) / abs( (4000 ) - (-5) + smooth )\n","        elif column == 'Direct sNIP [W/m^2]':\n","            data[column] = (data[column] - (-15) + smooth ) / abs( (1200) - (-15) + smooth )\n","        elif column == 'Azimuth Angle [degrees]':\n","            data[column] = (data[column] - (0) + smooth ) / abs( (360) - (0) + smooth )\n","        elif column == 'Tower Dry Bulb Temp [deg C]':\n","            data[column] = (data[column] - (-20) + smooth ) / abs( (32) - (-20) + smooth )\n","        elif column == 'Tower Wet Bulb Temp [deg C]':\n","            data[column] = (data[column] - (-20) + smooth ) / abs( (32) - (-20) + smooth )\n","        elif column == 'Tower Dew Point Temp [deg C]':\n","            data[column] = (data[column] - (-25) + smooth ) / abs( (32) - (-25) + smooth )\n","        elif column == 'Tower RH [%]':\n","            data[column] = (data[column] - (0) + smooth ) / abs( (100) - (0) + smooth )\n","        elif column == 'Total Cloud Cover [%]':\n","            data[column] = (data[column] - (0) + smooth ) / abs( (100) - (0) + smooth )\n","        elif column == 'Peak Wind Speed @ 6ft [m/s]':\n","            data[column] = (data[column] - (0) + smooth ) / abs( (30) - (0) + smooth )\n","        elif column == 'Avg Wind Direction @ 6ft [deg from N]':\n","            data[column] = (data[column] - (0) + smooth ) / abs( (360) - (0) + smooth )\n","        elif column == 'Station Pressure [mBar]':\n","            data[column] = (data[column] - (760) + smooth ) / abs( (850) - (760) + smooth )\n","        elif column == 'Precipitation (Accumulated) [mm]':\n","            data[column] = (data[column] - (0) + smooth ) / abs( (30) - (0) + smooth )\n","        elif column == 'Snow Depth [cm]':\n","            data[column] = (data[column] - (0) + smooth ) / abs( (30) - (0) + smooth )\n","        elif column == 'Moisture':\n","            data[column] = (data[column] - (0) + smooth ) / abs( (1) - (0) + smooth )\n","        elif column == 'Albedo (CMP11)':\n","            data[column] = (data[column] - (0) + smooth ) / abs( (2) - (0) + smooth )\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5MsC6MyL5sMk"},"source":["def process_train(base):\n","    original = pd.read_csv(os.path.join(base, \"train\", \"train.csv\"))\n","    original = normalize_columns(original)\n","    train = []\n","\n","    bar = pyprind.ProgBar(len(original['DATE (MM/DD)'].unique()), bar_char='█')\n","    for date in original['DATE (MM/DD)'].unique():\n","        items = original.loc[original['DATE (MM/DD)']==date].copy(deep=True)\n","        items['DATE (MM/DD)'] = items['DATE (MM/DD)'].apply(lambda x: get_date(x))\n","        items['MST'] = items['MST'].apply(lambda x: get_time(x))\n","\n","        day = get_date(date)\n","   \n","        for i in range(1, len(items)-9):\n","            data = items.iloc[i:i+10]\n","            if (data['Total Cloud Cover [%]']>0).all() and (data['Total Cloud Cover [%]']<1).all():\n","                entry = make_dict_train(data.to_numpy().transpose())\n","                filename = os.path.join(base, \"train\", day, \"{0}{1}.jpg\".format(day, entry['Time'][-1]))\n","                if os.path.isfile(filename):\n","                    entry['image'] = filename\n","                    train.append(entry)\n","\n","        bar.update()\n","\n","    return pd.DataFrame(train)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6FH6SPkaZF3X"},"source":["def process_test(base):\n","    test = []\n","\n","    bar = pyprind.ProgBar(len(sorted(os.listdir(os.path.join(base, \"test\")))), bar_char='█')\n","    for scenario in sorted(os.listdir(os.path.join(base, \"test\"))):\n","        original = pd.read_csv(os.path.join(base, \"test\", scenario, \"weather_data.csv\"))\n","        original = normalize_columns(original)  \n","\n","        for i in range(1, len(original)-9):\n","            entry = make_dict_test(original.iloc[i:i+10].to_numpy().transpose())\n","            entry['Scenario'] = scenario\n","            filename = os.path.join(base, \"test\", scenario, \"{0}.jpg\".format(entry[\"Time\"][-1]))\n","            if os.path.isfile(filename):\n","                entry['image'] = filename\n","                test.append(entry)\n","        bar.update()\n","\n","    return pd.DataFrame(test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v3cXpHyE8XZd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634914297249,"user_tz":-330,"elapsed":281264,"user":{"displayName":"Archish S me20b032","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9ll1qEcdMw2M-lzXJv5aJCpZWOiRrS0LtyzYpWw=s64","userId":"01577508935431199324"}},"outputId":"4f61c6af-d207-4e42-9e85-6ec79a9dbd9c"},"source":["train = process_train(base=\"/content/dataset/\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["0% [██████████████████████████████] 100% | ETA: 00:00:00\n","Total time elapsed: 00:04:39\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bc9AEfA79lEf","executionInfo":{"status":"ok","timestamp":1634914450166,"user_tz":-330,"elapsed":43114,"user":{"displayName":"Archish S me20b032","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9ll1qEcdMw2M-lzXJv5aJCpZWOiRrS0LtyzYpWw=s64","userId":"01577508935431199324"}},"outputId":"0e183db9-4e3d-4811-b0d1-98bf932f9098"},"source":["test = process_test(base=\"/content/dataset/\")\n","test['Time'] = test['Time'].apply(lambda x: x[9])\n","test = test.sort_values(by = ['Scenario', 'Time'])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["0% [██████████████████████████████] 100% | ETA: 00:00:00\n","Total time elapsed: 00:00:41\n"]}]},{"cell_type":"code","metadata":{"id":"d_5j9rMThfAK"},"source":["train.to_pickle(\"/content/dataset/processed_train.pkl\")\n","test.to_pickle(\"/content/dataset/processed_test.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"99d2qrtsOiDe"},"source":["# !cd \"/content/dataset\" && zip -r \"/content/drive/MyDrive/Events/Hackathons/shell.ai - noVowels/dataset/processed_dataset_new.zip\" *\n","\n","\n","# clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t79L0Iigm-O5"},"source":["train = pd.read_pickle(\"/content/dataset/processed_train.pkl\")\n","test = pd.read_pickle(\"/content/dataset/processed_test.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_8Efd0W51xca"},"source":["----"]},{"cell_type":"code","metadata":{"id":"IuBTn27D3kyV"},"source":["# train = pd.read_csv(\"/content/dataset/train/train.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"txenFk-zggrP"},"source":["---"]},{"cell_type":"code","metadata":{"id":"YoG7WD8F2oYV"},"source":["class CreateDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, base, past=8, future=12, image=256, dataset='train'):\n","        self.base = base\n","        self.past = past\n","        self.future = future\n","        self.image = image\n","        self.dataset = dataset\n","        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","        self.data = pd.read_pickle(os.path.join(base, f\"processed_{dataset}.pkl\"))\n","        self.files = []\n","\n","        self.init_dataset()\n","\n","    def image_transform(self, image):\n","        image = image.copy()\n","        image = cv2.resize(image, (self.image, self.image), interpolation=cv2.INTER_AREA)\n","        image = image/255.\n","        image = image.transpose((2, 0, 1))\n","        image = torch.from_numpy(image)\n","        if self.dataset == 'train':\n","            image = self.normalize(image)\n","        elif self.dataset == 'test':\n","            pass\n","        image = image.unsqueeze(0)\n","        return image\n","\n","    def data_transform(self, data, mode):\n","        data = data.copy()\n","        if mode == 'input':\n","            if self.dataset=='train':\n","                input = data[2:-1]\n","            elif self.dataset=='test':\n","                input = data[1:-2]\n","            input = np.concatenate(input).astype('float64').reshape(15, 10).transpose()\n","            input = torch.from_numpy(input)\n","            input = input.unsqueeze(0)\n","            return input\n","        elif mode == 'output':\n","            output = np.array([data[8][-1]]).astype('float64')\n","            output = torch.from_numpy(output)\n","            output = output.unsqueeze(0)\n","        return output\n","\n","    def init_dataset(self):\n","        if self.dataset == 'train':\n","            bar = pyprind.ProgBar(len(self.data['Date'].unique()), bar_char='█')\n","            for date in self.data['Date'].unique():\n","                data = self.data.loc[self.data['Date']==date]\n","                for item in range(self.past, len(data)-self.future, 1):\n","                    past = data[item-self.past+1:item+1]\n","                    future = data[item+1:item+self.future+1]\n","                    image_path = []\n","                    input_weather = torch.empty((0, 10, 15))\n","                    output_actual = torch.empty((0, 1))\n","                    for i in range(len(past)):\n","                        image_path.append(past.iloc[i][-1])\n","                        input_weather = torch.cat((input_weather, self.data_transform(past.iloc[i], mode='input')), dim=0)\n","                    for i in range(len(future)):\n","                        output_actual = torch.cat((output_actual, self.data_transform(future.iloc[i], mode='output')), dim=0)\n","\n","                    self.files.append({'input_images': image_path, 'input_weather': input_weather, 'output_actual': output_actual})\n","                bar.update()\n","        elif self.dataset == 'test':\n","            bar = pyprind.ProgBar(len(self.data['Scenario'].unique()), bar_char='█')\n","            for scenario in self.data['Scenario'].unique():\n","                data = self.data.loc[self.data['Scenario']==scenario]\n","                past = data.iloc[-self.past:]\n","                image_path = []\n","                input_weather = torch.empty((0, 10, 15))\n","                for i in range(len(past)):\n","                    image_path.append(past.iloc[i][-1])\n","                    input_weather = torch.cat((input_weather, self.data_transform(past.iloc[i], mode='input')), dim=0)\n","                self.files.append({'input_images': image_path, 'input_weather': input_weather})\n","                bar.update()\n","\n","    def __getitem__(self, index):\n","        data = self.files[index]\n","\n","        if self.dataset == 'train':\n","            input_image = torch.empty((0, 3, self.image, self.image))\n","            images = data['input_images']\n","            for path in images:\n","                image = cv2.imread(path, cv2.IMREAD_COLOR)\n","                image = self.image_transform(image)\n","                input_image = torch.cat((input_image, image), dim=0)\n","            input_weather = data['input_weather']\n","            output_actual = data['output_actual']\n","\n","            return input_image, input_weather, output_actual\n","        elif self.dataset == 'test':\n","            input_image = torch.empty((0, 3, self.image, self.image))\n","            images = data['input_images']\n","            for path in images:\n","                image = cv2.imread(path, cv2.IMREAD_COLOR)\n","                image = self.image_transform(image)\n","                input_image = torch.cat((input_image, image), dim=0)\n","            input_weather = data['input_weather']\n","\n","            return input_image, input_weather\n","\n","    def __len__(self):\n","        return len(self.files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P25PYTou0qh6"},"source":["base = \"/content/dataset\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgLn8VN98kwU"},"source":["trainset = CreateDataset(base, past=8, future=12, image=256, dataset='train')\n","testset = CreateDataset(base, past=8, future=12, image=256, dataset='test')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x49yLOPu2Zqf"},"source":["print(f\"Train: {len(trainset)}\")\n","print(f\"Test: {len(testset)}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D0YTHeGd8oc6"},"source":[""],"execution_count":null,"outputs":[]}]}